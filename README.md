# Encoder-Decoder-Transformer

Encoder-decoder architecture for decoder-only style next token prediction. Adds bidirectionality to instruct style large language models to mitigate decoder-only unidirectional context limits and enhance:

- Deeper understanding of full conversational context
- Ability to ground responses in structured knowledge
- Better generalization to new topics and domains
